{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.linear_model import RidgeClassifierCV, SGDClassifier, PassiveAggressiveClassifier,Perceptron,LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import pickle\n",
    "import os\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_file = os.path.join(base_dir, \"train_data_standardized.csv\")\n",
    "test_file = os.path.join(base_dir, \"test_data_standardized.csv\")\n",
    "\n",
    "# 载入数据集\n",
    "dataset = pd.read_csv(train_file)\n",
    "x_train = dataset.iloc[:, 1:]  # 从第二列开始\n",
    "y_train = dataset[['dic']].values.ravel()\n",
    "\n",
    "dataset_test = pd.read_csv(test_file)\n",
    "x_test = dataset_test.iloc[:, 1:]\n",
    "y_test = dataset_test[['dic']].values.ravel()\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)  # 5折分层交叉验证，重复5次\n",
    "n_jobs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'ventilation', 'vasopressin', 'crrt', 'myocardial_infarct', 'congestive_heart_failure', 'peripheral_vascular_disease', 'cerebrovascular_disease', 'dementia', 'chronic_pulmonary_disease', 'rheumatic_disease', 'peptic_ulcer_disease', 'mild_liver_disease', 'diabetes_without_cc', 'diabetes_with_cc', 'paraplegia', 'renal_disease', 'malignant_cancer', 'severe_liver_disease', 'metastatic_solid_tumor', 'aids']\n",
      "['sofa_score', 'age', 'los', 'scr_min', 'mdrd_est', 'scr_baseline', 'alt_min', 'alp_min', 'ast_min', 'sirs', 'lods', 'apsiii', 'wbc_max', 'basophils_abs_max', 'eosinophils_abs_min', 'lymphocytes_abs_min', 'monocytes_abs_min', 'neutrophils_abs_max', 'basophils_min', 'eosinophils_max', 'lymphocytes_min', 'monocytes_min', 'neutrophils_max', 'age_score', 'charlson_comorbidity_index', 'albumin_min', 'creatinine_max', 'sodium_min', 'inr_max', 'pt_max', 'ptt_max', 'hemoglobin_min', 'platelet_min', 'rbc_min', 'potassium_max', 'glucose_max', 'bicarbonate_min', 'bun_max', 'chloride_max', 'heart_rate_max', 'resp_rate_max', 'sbp_min', 'dbp_min', 'mbp_min']\n"
     ]
    }
   ],
   "source": [
    "# 设定阈值，比如非重复值个数少于一定数量时认为是分类变量\n",
    "threshold = 2 # 可根据实际需求调整\n",
    "\n",
    "# 自动提取列名，根据唯一值数量\n",
    "columns_by_unique_count = x_train.nunique()  # 每列的唯一值个数\n",
    "categorical_cols = columns_by_unique_count[columns_by_unique_count <= threshold].index.tolist()\n",
    "categorical_indices = [x_train.columns.get_loc(col) for col in categorical_cols]\n",
    "continuous_cols = columns_by_unique_count[columns_by_unique_count > threshold].index.tolist()\n",
    "print(categorical_cols)\n",
    "print(continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(model, X, threshold=0.5):\n",
    "    \"\"\"使用模型进行预测，并根据模型类型选择预测方法。\"\"\"\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        y_pred = model.decision_function(X)\n",
    "        y_pred_label = (y_pred > 0).astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict_proba(X)[:, 1]\n",
    "        y_pred_label = (y_pred > threshold).astype(int)\n",
    "    return y_pred, y_pred_label\n",
    "\n",
    "def evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"在训练集和测试集上评估模型，并保存模型文件。\"\"\"\n",
    "    # 使用最好的模型进行训练集预测\n",
    "    y_train_pred, y_train_pred_label = predict_with_model(model, x_train)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred_label)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred_label)\n",
    "    \n",
    "    # 在测试集上进行预测\n",
    "    y_test_pred, y_test_pred_label = predict_with_model(model, x_test)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred_label)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred_label)\n",
    "\n",
    "    # 保存模型，文件名为模型类型\n",
    "    # 创建模型存储目录（如果不存在）\n",
    "    # os.makedirs(\"model\", exist_ok=True)\n",
    "    # # 保存模型，路径包含子目录\n",
    "    # model_name = type(model.named_steps[\"model\"]).__name__\n",
    "    # model_filename = os.path.join(\"model\", f\"{model_name}.pkl\")\n",
    "    # with open(model_filename, \"wb\") as f:\n",
    "    #     pickle.dump(model, f)\n",
    "    # print(f\"模型已保存为: {model_filename}\")\n",
    "    \n",
    "    # 打印性能结果\n",
    "    print(f\"Training AUC: {train_auc}\")\n",
    "    print(f\"Training ACC: {train_acc}\")\n",
    "    print(f\"Training F1 Score: {train_f1}\")\n",
    "    print(f\"Test AUC: {test_auc}\")\n",
    "    print(f\"Test ACC: {test_acc}\")\n",
    "    print(f\"Test F1 Score: {test_f1}\")\n",
    "\n",
    "    return {\n",
    "        'train_auc': train_auc,\n",
    "        'train_f1': train_f1,\n",
    "        'train_acc': train_acc,\n",
    "        'test_auc': test_auc,\n",
    "        'test_f1': test_f1,\n",
    "        'test_acc': test_acc\n",
    "    }\n",
    "\n",
    "# def get_top_features_shap(model, X, output_file=\"./output/shap_feature_importance.xlsx\"):\n",
    "#     \"\"\"\n",
    "#     Parameters:\n",
    "#     - model: 训练好的模型。\n",
    "#     - X: 用于计算 SHAP 值的特征数据（通常是训练数据）。\n",
    "#     - output_file: 保存 SHAP 排名和 SHAP 值的 Excel 文件名（默认为 \"shap_feature_importance.xlsx\"）。\n",
    "\n",
    "#     Returns:\n",
    "#     - top_feature_list: 包含按 SHAP 排序的特征名称的列表。\n",
    "#     \"\"\"\n",
    "#     # 创建解释器\n",
    "#     explainer = shap.Explainer(model.predict, X)\n",
    "#     shap_values = explainer(X)\n",
    "\n",
    "#     # 获取特征重要性\n",
    "#     importance = np.abs(shap_values.values).mean(axis=0)\n",
    "#     # 获取特征名称\n",
    "#     feature_names = X.columns\n",
    "\n",
    "#     # 创建一个 DataFrame 来存储特征及其重要性\n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'Feature': feature_names,\n",
    "#         'Importance': importance,\n",
    "#         'SHAP Value': np.mean(shap_values.values, axis=0)\n",
    "#     })\n",
    "\n",
    "#     # 按重要性排序并提取前 N 个特征\n",
    "#     importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "#     # 将特征的名称保存到列表中\n",
    "#     top_feature_list = importance_df['Feature'].tolist()\n",
    "\n",
    "#     # 保存排名和 SHAP 值到 Excel 文件\n",
    "#     importance_df.to_excel(output_file, index=False)\n",
    "\n",
    "#     print(f\"Top features based on SHAP values saved to {output_file}\")\n",
    "#     print(importance_df)\n",
    "\n",
    "#     # SHAP 排序图\n",
    "#     shap.plots.bar(shap_values)\n",
    "\n",
    "#     return top_feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 6480 candidates, totalling 162000 fits\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=1)\n",
    "param_grid_rfc = {\n",
    "    \"model__n_estimators\": np.arange(80, 100, 1),\n",
    "    \"model__criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"model__max_features\": np.arange(0.1, 1, 0.1),\n",
    "    \"model__max_depth\": np.arange(1, 13, 1)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', rfc)\n",
    "])\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_rfc = GridSearchCV(pipeline, param_grid_rfc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_rfc.fit(x_train, y_train)\n",
    "best_model_rfc = grid_search_rfc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(rfc).__name__)\n",
    "print(f\"Best parameters: {grid_search_rfc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_rfc.best_score_}\")\n",
    "\n",
    "results_rfc = evaluate_model(best_model_rfc, x_train, y_train, x_test, y_test)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Training AUC: {results_rfc['train_auc']}\")\n",
    "print(f\"Training ACC: {results_rfc['train_acc']}\")\n",
    "print(f\"External validation AUC: {results_rfc['test_auc']}\")\n",
    "print(f\"Training F1 Score: {results_rfc['train_f1']}\")\n",
    "print(f\"External validation ACC: {results_rfc['test_acc']}\")\n",
    "print(f\"External validation F1 Score: {results_rfc['test_f1']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 8 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(random_state=1)\n",
    "\n",
    "param_grid_lr={\n",
    "    \"model__fit_intercept\":[True,False],\n",
    "    \"model__penalty\":['l1','l2'],\n",
    "    \"model__solver\":['liblinear','saga'],\n",
    "    \"model__max_iter\": [2500]  # 增加迭代次数\n",
    "}\n",
    "\n",
    "# 创建 Pipeline：过采样 → 模型训练\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', lr)\n",
    "])\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_lr = GridSearchCV(pipeline, param_grid_lr, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_lr.fit(x_train, y_train)\n",
    "best_model_lr = grid_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Best parameters: {'model__fit_intercept': True, 'model__max_iter': 2500, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
      "Best F1 Score (cross-validation): 0.216483583345964\n",
      "模型已保存为: model/LogisticRegression.pkl\n",
      "Training AUC: 0.7518382122484799\n",
      "Training ACC: 0.8581571473650994\n",
      "Training F1 Score: 0.23748939779474132\n",
      "Test AUC: 0.7484156202195438\n",
      "Test ACC: 0.8694006309148264\n",
      "Test F1 Score: 0.2935153583617747\n"
     ]
    }
   ],
   "source": [
    "print(type(lr).__name__)\n",
    "print(f\"Best parameters: {grid_search_lr.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_lr.best_score_}\")\n",
    "\n",
    "results_lr = evaluate_model(best_model_lr, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbd = GradientBoostingClassifier(random_state = 1)#这个模型比较耗时，参数空间比较大，粗略检索与精细检索结合\n",
    "param_grid_gbd={\n",
    "    \"model__learning_rate\":np.arange(0.2,0.4,0.04),\n",
    "    \"model__n_estimators\":np.arange(50,100,4),\n",
    "    \"model__subsample\":np.arange(0.6,0.8,0.04),\n",
    "    \"model__max_features\":np.arange(0.01,0.2,0.04),\n",
    "    \"model__max_depth\":np.arange(1,13,1)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', gbd)\n",
    "])\n",
    "\n",
    "'''\n",
    "原始字典\n",
    "param_grid_gbd={\n",
    "    \"model__learning_rate\":np.arange(0.2,0.4,0.01),\n",
    "    \"model__n_estimators\":np.arange(50,100,1),\n",
    "    \"model__subsample\":np.arange(0.6,0.8,0.01),\n",
    "    \"model__max_features\":np.arange(0.01,0.2,0.01),\n",
    "    \"model__max_depth\":np.arange(1,13,1)\n",
    "}\n",
    "'''\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_gbd = GridSearchCV(pipeline, param_grid_gbd, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_gbd.fit(x_train, y_train)\n",
    "best_model_gbd = grid_search_gbd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(gbd).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_gbd.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_gbd.best_score_}\")\n",
    "\n",
    "results_gbd = evaluate_model(best_model_gbd, x_train, y_train, x_test, y_test)\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_gbd, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb=BernoulliNB()\n",
    "param_grid_bnb={\n",
    "    \"model__alpha\":np.linspace(0,100,100),\n",
    "    \"model__fit_prior\":[True,False],\n",
    "    \"model__binarize\":np.linspace(0,10,100),\n",
    "    \"model__class_prior\":[None]\n",
    "}\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', bnb)\n",
    "])\n",
    "# 执行超参数搜索\n",
    "grid_search_bnb = GridSearchCV(pipeline, param_grid_bnb, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_bnb.fit(x_train, y_train)\n",
    "best_model_bnb = grid_search_bnb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(bnb).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_bnb.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_bnb.best_score_}\")\n",
    "\n",
    "results_bnb = evaluate_model(best_model_bnb, x_train, y_train, x_test, y_test)\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_bnb, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 KNN 模型\n",
    "knn = KNeighborsClassifier()# 无需random_state\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', knn)\n",
    "])\n",
    "# 定义超参数搜索范围\n",
    "param_grid_knn = {\n",
    "    \"model__n_neighbors\": np.arange(1,16,1),\n",
    "    \"model__weights\": ['uniform', 'distance'],\n",
    "    \"model__metric\": ['euclidean', 'manhattan', 'minkowski'],\n",
    "    \"model__p\": [1, 2]  # 1 = 曼哈顿距离, 2 = 欧几里得距离\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_knn = GridSearchCV(pipeline, param_grid_knn, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_knn.fit(x_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model_knn = grid_search_knn.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(knn).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_knn.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_knn.best_score_}\")\n",
    "\n",
    "results_knn = evaluate_model(best_model_knn, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 9000 candidates, totalling 225000 fits\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreeClassifier(random_state=1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', et)\n",
    "])\n",
    "\n",
    "# 定义超参数搜索范围\n",
    "param_grid_et = {\n",
    "    \"model__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"model__splitter\": [\"random\", \"best\"],\n",
    "    \"model__max_depth\": [3, 5, 10, 20, 30],\n",
    "    \"model__min_samples_split\": np.arange(2,11,1),\n",
    "    \"model__min_samples_leaf\": np.arange(1,11,1),\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_et = GridSearchCV(pipeline, param_grid_et, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_et.fit(x_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model_et = grid_search_et.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {grid_search_et.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_et.best_score_}\")\n",
    "\n",
    "print(type(et).__name__)\n",
    "results_et = evaluate_model(best_model_et, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(random_state = 1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', etc)\n",
    "])\n",
    "param_grid_etc={\n",
    "    \"model__n_estimators\":np.arange(1,100,1),\n",
    "    #\"model__max_samples\":np.arange(0.01,0.1,0.01),\n",
    "    \"model__criterion\":['gini', 'entropy', 'log_loss'],\n",
    "    \"model__max_features\":np.arange(0.01,0.1,0.01),\n",
    "    \"model__max_depth\":np.arange(1,13,1)\n",
    "}\n",
    "\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_etc = GridSearchCV(pipeline, param_grid_etc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_etc.fit(x_train, y_train)\n",
    "best_model_etc = grid_search_etc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(etc).__name__)\n",
    "print(f\"Best parameters: {grid_search_etc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_etc.best_score_}\")\n",
    "\n",
    "results_etc = evaluate_model(best_model_etc, x_train, y_train, x_test, y_test)\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_etc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 99 candidates, totalling 2475 fits\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(random_state=1, penalty='l1',dual = False, loss = 'squared_hinge')\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', lsvc)\n",
    "])\n",
    "param_grid_lsvc= {'model__C':np.arange(0.01,1,0.01)}\n",
    "\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_lsvc = GridSearchCV(pipeline, param_grid_lsvc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_lsvc.fit(x_train, y_train)\n",
    "best_model_lsvc = grid_search_lsvc.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "Best parameters: {'model__C': 0.01}\n",
      "Best F1 Score (cross-validation): 0.2155902391718928\n",
      "Training AUC: 0.7643388797220122\n",
      "Training F1 Score: 0.2259810554803789\n",
      "Training ACC: 0.8404017857142857\n",
      "External validation AUC: 0.7766296791079363\n",
      "External validation F1 Score: 0.23497267759562843\n",
      "External validation ACC: 0.84375\n"
     ]
    }
   ],
   "source": [
    "print(type(lsvc).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_lsvc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_lsvc.best_score_}\")\n",
    "\n",
    "results_lsvc = evaluate_model(best_model_lsvc, x_train, y_train, x_test, y_test)\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_lsvc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NonLinear_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', svc)\n",
    "])\n",
    "param_grid_svc = {'model__C':np.arange(100,150,1),\n",
    "              'model__gamma':np.arange(0.0001,0.001,0.0001),\n",
    "              'model__kernel':['poly','rbf','sigmoid']}  \n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_svc = GridSearchCV(pipeline, param_grid_svc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_svc.fit(x_train, y_train)\n",
    "best_model_svc = grid_search_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(svc).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_svc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_svc.best_score_}\")\n",
    "\n",
    "results_svc = evaluate_model(best_model_svc, x_train, y_train, x_test, y_test)\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_svc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(random_state = 1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', abc)\n",
    "])\n",
    "param_grid_abc={\n",
    "    \"model__n_estimators\":np.arange(400,500,1),\n",
    "    \"model__learning_rate\":np.arange(0.1,0.2,0.01),\n",
    "    \"model__algorithm\":['SAMME','SAMME.R']\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_abc = GridSearchCV(pipeline, param_grid_abc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_abc.fit(x_train, y_train)\n",
    "best_model_abc = grid_search_abc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(abc).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_abc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_abc.best_score_}\")\n",
    "\n",
    "results_abc = evaluate_model(best_model_abc, x_train, y_train, x_test, y_test)\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_abc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 648 candidates, totalling 16200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louhao/.conda/envs/mnf2/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', dtc)\n",
    "])\n",
    "param_grid_dtc={\n",
    "    \"model__criterion\":['gini','entropy','log_loss'],\n",
    "    \"model__splitter\":['best','random'],\n",
    "    #\"model__min_samples_leaf\":(0.001,0.01,0.001),\n",
    "    #\"model__min_samples_split\":(0.001,0.01,0.001),\n",
    "    \"model__max_features\":np.arange(1,10,1),\n",
    "    #\"model__max_features\":['auto', 'sqrt', 'log2'],#\"max_features\"要不要设置值应该尝试\n",
    "    \"model__max_depth\":np.arange(1,13,1)\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_dtc = GridSearchCV(pipeline, param_grid_dtc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_dtc.fit(x_train, y_train)\n",
    "best_model_dtc = grid_search_dtc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Best parameters: {'model__criterion': 'gini', 'model__max_depth': 2, 'model__max_features': 5, 'model__splitter': 'best'}\n",
      "Best F1 Score (cross-validation): 0.1929815995653992\n",
      "Training AUC: 0.7407050441809182\n",
      "Training F1 Score: 0.19319227230910763\n",
      "Training ACC: 0.7553013392857143\n",
      "External validation AUC: 0.7688186700836991\n",
      "External validation F1 Score: 0.23391812865497075\n",
      "External validation ACC: 0.7806919642857143\n"
     ]
    }
   ],
   "source": [
    "print(type(dtc).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_dtc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_dtc.best_score_}\")\n",
    "\n",
    "results_dtc = evaluate_model(best_model_dtc, x_train, y_train, x_test, y_test)\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_dtc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 40 candidates, totalling 1000 fits\n"
     ]
    }
   ],
   "source": [
    "rccv =RidgeClassifierCV()\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', rccv)\n",
    "])\n",
    "param_grid_rccv={\n",
    "    \"model__fit_intercept\":[True,False],\n",
    "    \"model__alphas\":np.arange(38,40,0.1)\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_rccv = GridSearchCV(pipeline, param_grid_rccv, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_rccv.fit(x_train, y_train)\n",
    "best_model_rccv = grid_search_rccv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifierCV\n",
      "Best parameters: {'model__alphas': 39.50000000000002, 'model__fit_intercept': False}\n",
      "Best F1 Score (cross-validation): 0.2124291796099841\n",
      "Training AUC: 0.7508340144236949\n",
      "Training F1 Score: 0.2211126961483595\n",
      "Training ACC: 0.84765625\n",
      "External validation AUC: 0.7475871752228797\n",
      "External validation F1 Score: 0.20869565217391303\n",
      "External validation ACC: 0.84765625\n"
     ]
    }
   ],
   "source": [
    "print(type(rccv).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_rccv.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_rccv.best_score_}\")\n",
    "\n",
    "results_rccv = evaluate_model(best_model_rccv, x_train, y_train, x_test, y_test)\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_rccv, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc=SGDClassifier(random_state=1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', sgdc)\n",
    "])\n",
    "param_grid_sgdc={\n",
    "    \"model__loss\":['hinge','log_loss','modified_huber','squared_hinge','perceptron','squared_error','huber','epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "    \"model__penalty\":['l2','l1','elasticnet'],\n",
    "    \"model__alpha\":np.arange(0.01,0.1,0.01),\n",
    "    \"model__l1_ratio\":np.arange(0.1,0.5,0.1),\n",
    "    \"model__fit_intercept\":[True,False],\n",
    "    \"model__learning_rate\":['optimal','invscaling','adaptive']\n",
    "    #\"learning_rate\":np.arange(0.01,1,0.01)\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_sgdc = GridSearchCV(pipeline, param_grid_sgdc, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_sgdc.fit(x_train, y_train)\n",
    "best_model_sgdc = grid_search_sgdc.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sgdc).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_sgdc.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_sgdc.best_score_}\")\n",
    "results_sgdc = evaluate_model(best_model_sgdc, x_train, y_train, x_test, y_test)\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_sgdc, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=Perceptron(random_state=1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', p)\n",
    "])\n",
    "param_grid_p={\n",
    "    \"model__penalty\":['l2','l1','elasticnet'],\n",
    "    \"model__alpha\":np.arange(0.000001,0.0001,0.000001),\n",
    "    \"model__fit_intercept\":[True,False]\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_p = GridSearchCV(pipeline, param_grid_p, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_p.fit(x_train, y_train)\n",
    "best_model_p = grid_search_p.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(p).__name__)\n",
    "print(f\"Best parameters: {grid_search_p.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_p.best_score_}\")\n",
    "results_p = evaluate_model(best_model_p, x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_p, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac=PassiveAggressiveClassifier(random_state=1)\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', pac)\n",
    "])\n",
    "param_grid_pac={\n",
    "    \"model__C\":np.arange(0.001,1.0,0.001),\n",
    "    \"model__fit_intercept\":[True,False]\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_pac = GridSearchCV(pipeline, param_grid_pac, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_pac.fit(x_train, y_train)\n",
    "best_model_pac = grid_search_pac.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pac).__name__)\n",
    "print(f\"Best parameters: {grid_search_pac.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_pac.best_score_}\")\n",
    "results_pac = evaluate_model(best_model_pac, x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "#rfc_top_feature_list = get_top_features_shap(best_model_pac, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 25 folds for each of 10 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# 定义 GaussianNB 模型\n",
    "nb = GaussianNB()\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTENC(categorical_features=categorical_indices, random_state=1)),\n",
    "    ('model', nb)\n",
    "])\n",
    "# 超参数搜索范围\n",
    "param_grid_nb = {\n",
    "    \"model__var_smoothing\": np.logspace(-9, 1, 10)  # 设定一个平滑参数，防止概率为 0\n",
    "}\n",
    "\n",
    "# 执行超参数搜索\n",
    "grid_search_nb = GridSearchCV(pipeline, param_grid_nb, cv=cv, scoring='f1', n_jobs=n_jobs, verbose=1)\n",
    "grid_search_nb.fit(x_train, y_train)\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model_nb = grid_search_nb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "Best parameters: {'model__var_smoothing': 10.0}\n",
      "Best F1 Score (cross-validation): 0.19897387176073134\n",
      "Training AUC: 0.7891754946822959\n",
      "Training ACC: 0.7869990533291259\n",
      "Training F1 Score: 0.22145328719723184\n",
      "Test AUC: 0.7832215442029351\n",
      "Test ACC: 0.7867507886435331\n",
      "Test F1 Score: 0.2028301886792453\n"
     ]
    }
   ],
   "source": [
    "print(type(nb).__name__)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_nb.best_params_}\")\n",
    "print(f\"Best F1 Score (cross-validation): {grid_search_nb.best_score_}\")\n",
    "\n",
    "# 评估模型\n",
    "results_nb = evaluate_model(best_model_nb, x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
